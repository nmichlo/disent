# @package _global_

dsettings:
  trainer:
    cuda: TRUE
  storage:
    logs_dir: 'logs'
    data_root: '${oc.env:HOME}/workspace/research/disent/data/dataset'
  dataset:
    prepare: TRUE
    try_in_memory: TRUE

datamodule:
  gpu_augment: FALSE
  prepare_data_per_node: TRUE
  dataloader:
    num_workers: 32  # max 128, more than 16 doesn't really seem to help (tested on batch size 256*3)?
    pin_memory: ${dsettings.trainer.cuda}
    batch_size: ${settings.dataset.batch_size}

hydra:
  job:
    name: 'disent'
  run:
    dir: '${dsettings.storage.logs_dir}/hydra_run/${now:%Y-%m-%d_%H-%M-%S}_${hydra.job.name}'
  sweep:
    dir: '${dsettings.storage.logs_dir}/hydra_sweep/${now:%Y-%m-%d_%H-%M-%S}_${hydra.job.name}'
    subdir: '${hydra.job.id}' # hydra.job.id is not available for dir
